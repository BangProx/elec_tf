{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298a8b2-6510-4fb2-90f7-1def109b74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas import to_datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_absolute_error, r2_score,mean_squared_error\n",
    "import gc\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad35f86-f75e-448e-bf3d-934a445e74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kepco = pd.read_csv('kepcoTotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c0801-f261-4d2d-9cf0-fbbf49b97881",
   "metadata": {},
   "outputs": [],
   "source": [
    "kepco.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfcb1d-65ce-4d6a-bc0d-220a1795842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(kepco['Hourly Sum'], label='Hourly Sum', color='blue')\n",
    "\n",
    "plt.title('Hourly Sum')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cab1b-7016-4678-a263-720186398e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of data(kepco) : ',len(kepco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde09825-9367-4b1d-8e75-2df4fc368a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Hourly Time'을 datetime 객체로 변환\n",
    "kepco['Hourly Time'] = pd.to_datetime(kepco['Hourly Time'], format='%Y년 %m월 %d일 %H시')\n",
    "\n",
    "#추가적인 시간 관련 특징을 추출\n",
    "kepco['weekday'] = kepco['Hourly Time'].dt.dayofweek \n",
    "kepco['hour'] = kepco['Hourly Time'].dt.hour         \n",
    "kepco['month'] = kepco['Hourly Time'].dt.month\n",
    "kepco.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87711887-a5e5-4e74-8c05-366a4972c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "Q1 = kepco['Hourly Sum'].quantile(0.25)\n",
    "Q3 = kepco['Hourly Sum'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57730c3-5425-422e-9098-a7e66603f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거 반영\n",
    "median = kepco['Hourly Sum'].median()\n",
    "kepco.loc[(kepco['Hourly Sum'] < lower_bound) | (kepco['Hourly Sum'] > upper_bound), 'Hourly Sum'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a218b2-2ee4-43e3-83fe-928083a9f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거후 데이터셋\n",
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(kepco['Hourly Sum'], label='Hourly Sum', color='blue')\n",
    "\n",
    "plt.title('Hourly Sum')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22d271-fc1b-4534-932e-dc4ee4f54933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24시간 단위로 scaling하는 함수\n",
    "def scale_in_chunks(data, chunk_size):\n",
    "    scaled_data = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk = data[i:i + chunk_size]\n",
    "        chunk_reshaped = chunk.reshape(-1, 1)\n",
    "        if i == 0 or len(chunk) == chunk_size:\n",
    "            scaled_chunk = scaler.fit_transform(chunk_reshaped)\n",
    "        else:\n",
    "            scaled_chunk = scaler.transform(chunk_reshaped)\n",
    "        scaled_data.extend(scaled_chunk.flatten())\n",
    "    return np.array(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a5010-187d-49fd-ab50-0614ed3bd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Hourly Sum' 전력 사용량 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "hourly_sum = np.array(kepco['Hourly Sum'])\n",
    "month = np.array(kepco['month'])\n",
    "hour = np.array(kepco['hour'])\n",
    "\n",
    "scaled_hourly_sum = scale_in_chunks(hourly_sum, 24)\n",
    "scaled_month = scale_in_chunks(month, 24)\n",
    "scaled_hour = scale_in_chunks(hour, 24)\n",
    "\n",
    "\n",
    "kepco['Hourly Sum'] = scaled_hourly_sum\n",
    "kepco['month'] = scaled_month\n",
    "kepco['hour'] = scaled_hour\n",
    "\n",
    "# 데이터 프레임에서 필요한 열만 선택\n",
    "input_kepco = kepco[['Hourly Sum', 'month','hour']]\n",
    "input_kepco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb142aa-2540-4eb5-80f4-c00b2ba026b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kepco = input_kepco[:int(0.7*len(input_kepco))]\n",
    "temp = input_kepco[int(0.7*len(input_kepco)):]\n",
    "test_kepco =temp[int(len(temp)*0.5):] \n",
    "val_kepco = temp - temp[int(len(temp)*0.5):]\n",
    "train_kepco.shape, test_kepco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1157ab6-bbc9-4e71-a8b5-fdb1f206ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 168  \n",
    "prediction_length = 24  \n",
    "\n",
    "# 시퀀스 데이터를 생성하는 함수\n",
    "def create_sequences(kepco, sequence_length, prediction_length):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(kepco) - sequence_length - prediction_length + 1):\n",
    "        X.append(kepco[i:(i + sequence_length)].values)\n",
    "        y.append(kepco[(i + sequence_length):(i + sequence_length + prediction_length)]['Hourly Sum'].values)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = create_sequences(train_kepco, sequence_length, prediction_length)\n",
    "X_val, y_val = create_sequences(val_kepco, sequence_length, prediction_length)\n",
    "X_test, y_test = create_sequences(test_kepco, sequence_length, prediction_length)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ea1e16-1959-4478-9a2d-9138d930d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.input_linear = nn.Linear(input_dim, model_dim)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, sequence_length, model_dim))\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim, nhead=num_heads, dim_feedforward=model_dim * 4, dropout=dropout,batch_first = True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.output_linear = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_linear(x) + self.positional_encoding\n",
    "        mask = self.generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "        x = self.transformer_encoder(x, mask)\n",
    "        return self.output_linear(x[:, -1, :])\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "input_dim = X_train.shape[-1]  # 입력 차원\n",
    "model_dim = 512  # 모델의 특징 차원\n",
    "num_heads = 8  # 어텐션 헤드의 수\n",
    "num_layers = 4  # 인코더 레이어의 수\n",
    "output_dim = y_train.shape[-1]  # 출력 차원\n",
    "\n",
    "model = TransformerModel(input_dim, model_dim, num_heads, num_layers, output_dim)\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 모델 요약\n",
    "model, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a986a6-556d-4770-b9f1-a0c5ecd2cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6297f-e9bf-4dab-9e6d-7494c62f3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# PyTorch에서 사용할 데이터를 tensor로 변환\n",
    "X_train_tensor = torch.Tensor(X_train).to(device)\n",
    "y_train_tensor = torch.Tensor(y_train).to(device)\n",
    "X_val_tensor = torch.Tensor(X_val).to(device)\n",
    "y_val_tensor = torch.Tensor(y_val).to(device)\n",
    "\n",
    "# TensorDataset과 DataLoader를 사용하여 데이터 로드\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=False)\n",
    "\n",
    "val_data = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3257e13-7eae-4a43-87d4-a2335f91eb02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    for epoch in range((num_epochs)):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                val_loss = criterion(output, target).item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53f2ef2-e2e3-4882-9685-0cc0f5e8aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training loop\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82563842",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tensor = torch.tensor(y_test,dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test,dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0c72f-d8a2-4a79-88ea-0c217ec8494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tensor = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(102):\n",
    "        temp = model(X_test_tensor[i*100:(i+1)*100])\n",
    "        predictions_tensor.extend(temp)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    temp = model(X_test_tensor[10200:10221])\n",
    "    predictions_tensor.extend(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8a18e-0d70-4ade-8758-6ff9f40dfb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tensor = [tensor.cpu() for tensor in predictions_tensor]\n",
    "predictions = np.array(predictions_tensor)\n",
    "y_test = np.array(y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04279863-0214-407e-897f-c7f0be64bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test,predictions)\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, predictions): \n",
    "    y_test, predictions = np.array(y_test), np.array(predictions)\n",
    "    non_zero_mask = y_test != 0  \n",
    "    return np.mean(np.abs((y_test[non_zero_mask] - predictions[non_zero_mask]) / y_test[non_zero_mask])) * 100\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "r_squared = r2_score(y_test, predictions).round(5)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "print(f\"R-squared (R²): {r_squared}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e76cae-5e59-4a46-a302-92af83ceebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 6))\n",
    "plt.plot(predictions[155], label='Predictions', color='blue', marker='o') \n",
    "plt.plot(y_test[155], label='Ground Truth', color='red', marker='x')  \n",
    "\n",
    "\n",
    "plt.title('Time Series Comparison of Predictions and Ground Truth')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607e7eb-442f-4f0b-b6d6-a22d3c9eefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions.reshape(-1,1)\n",
    "y_test_1d = y_test.reshape(-1,1)\n",
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44f652-b1a8-4ef0-9cb7-44259731928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(predictions[200], label='Predictions', color='blue', marker='o') \n",
    "plt.plot(y_test[200], label='Ground Truth', color='red', marker='x')\n",
    "\n",
    "plt.title('Time Series Comparison of Predictions and Ground Truth')\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Hourly Sum')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0cfbd-a39b-4055-a283-8c0abaf54efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_1d = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160738a-1346-470f-9876-231891adab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "Time Series Comparison of Predictions and Ground Truth\n",
    "plt.xlabel('Time Points')\n",
    "plt.ylabel('Hourly Sum') \n",
    "plt.grid()\n",
    "plt.plot(y_test_1d, label='Ground Truth', color='red', marker='x')\n",
    "plt.plot(y_train_1d,label='Predictions', color='blue', marker='o') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec32906-1ba3-41b0-b44b-e6d7bf99d2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
